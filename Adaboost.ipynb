{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label  id\n",
      "0  [16, 231, 543, 5, 15, 43, 8282, 94, 231, 1129,...      1   0\n",
      "1  [16, 4046, 138, 10, 2, 1809, 2007, 3763, 14, 4...      1   1\n",
      "2  [1108, 16550, 3, 6168, 3, 160, 284, 19, 49, 46...      1   2\n",
      "3  [1802, 27, 16, 25, 48, 451, 632, 3, 2, 2164, 2...      1   3\n",
      "4  [16, 19, 302, 93, 97, 43, 952, 118, 1, 16, 528...      1   4\n",
      "                                                text  label    id\n",
      "0  [12, 920, 7, 1266, 28, 9884, 1640, 116, 11, 13...      1  5000\n",
      "1  [783, 397, 253, 5797, 9379, 22, 793, 11838, 10...      1  5001\n",
      "2  [888, 14851, 323, 9, 27, 1377, 584, 195, 3, 13...      1  5002\n",
      "3  [228, 1161, 5815, 379, 9, 941, 10, 2, 316, 4, ...      1  5003\n",
      "4  [736, 19, 37, 813, 45, 6723, 27, 626, 8, 2, 34...      1  5004\n"
     ]
    }
   ],
   "source": [
    "#  Load the data\n",
    "domain1_train_data = pd.read_json('domain1_train_data.json', lines=True)\n",
    "domain2_train_data = pd.read_json('domain2_train_data.json', lines=True)\n",
    "\n",
    "\n",
    "print(domain1_train_data.head())\n",
    "print(domain2_train_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  label     id\n",
      "3833   [12, 155, 7, 193, 63, 10, 6467, 857, 14, 2672,...      0   8833\n",
      "11415  [2522, 988, 931, 3, 52, 206, 7143, 988, 931, 3...      0  16415\n",
      "6312   [8, 2, 446, 4, 3366, 619, 156, 6463, 7692, 3, ...      0  11312\n",
      "6296   [43, 7598, 865, 8, 7708, 172, 9, 81, 218, 5, 4...      0  11296\n",
      "3667   [7760, 323, 87, 14, 8049, 13, 22, 2203, 18, 98...      0   8667\n"
     ]
    }
   ],
   "source": [
    "# get machine and human data\n",
    "machine = domain2_train_data[domain2_train_data['label'] == 0]\n",
    "human = domain2_train_data[domain2_train_data['label'] == 1]\n",
    "\n",
    "# count the number of samples in each class\n",
    "n_machine = len(machine)\n",
    "n_human = len(human)\n",
    "\n",
    "# if the number of samples in 'machine' is greater than the number of samples in 'human'\n",
    "if n_machine > n_human:\n",
    "    machine = machine.sample(n_human)\n",
    "\n",
    "# combine the balanced data\n",
    "domain2_train_data_balanced = pd.concat([machine, human])\n",
    "\n",
    "print(domain2_train_data_balanced.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the two datasets\n",
    "combined_data = pd.concat([domain1_train_data, domain2_train_data_balanced])\n",
    "\n",
    "\n",
    "# get the features and labels\n",
    "X = combined_data['text']\n",
    "y = combined_data['label']\n",
    "\n",
    "\n",
    "# # split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将词语列表转换为字符串\n",
    "X_train_str = [' '.join(map(str, lst)) for lst in X_train]\n",
    "X_val_str = [' '.join(map(str, lst)) for lst in X_val]\n",
    "\n",
    "# tf-idf向量化\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train_str)\n",
    "X_val_vec = vectorizer.transform(X_val_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the base estimator (weak learner)\n",
    "base_estimator = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# Define the AdaBoost classifier\n",
    "adaboost_model = AdaBoostClassifier(base_estimator=base_estimator, random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation \n",
    "grid_search = GridSearchCV(estimator=adaboost_model, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_search_result = grid_search.fit(X_train_vec, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search_result.best_params_)\n",
    "\n",
    "# Evaluate the best model on the validation set\n",
    "best_adaboost_model = grid_search_result.best_estimator_\n",
    "adaboost_predictions = best_adaboost_model.predict(X_val_vec)\n",
    "accuracy = accuracy_score(y_val, adaboost_predictions)\n",
    "print(\"Validation Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
    "Best Hyperparameters: {'learning_rate': 0.5, 'n_estimators': 200}\n",
    "Validation Accuracy: 0.68828125\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the base estimator (weak learner)\n",
    "base_estimator = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# Define the AdaBoost classifier\n",
    "adaboost_model = AdaBoostClassifier(base_estimator=base_estimator, random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 250, 300, 350],\n",
    "    'learning_rate': [0.5]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation \n",
    "grid_search = GridSearchCV(estimator=adaboost_model, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_search_result = grid_search.fit(X_train_vec, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search_result.best_params_)\n",
    "\n",
    "# Evaluate the best model on the validation set\n",
    "best_adaboost_model_2 = grid_search_result.best_estimator_\n",
    "adaboost_predictions_2 = best_adaboost_model_2.predict(X_val_vec)\n",
    "accuracy_2 = accuracy_score(y_val, adaboost_predictions_2)\n",
    "print(\"Validation Accuracy:\", accuracy_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
    "Best Hyperparameters: {'learning_rate': 0.5, 'n_estimators': 300}\n",
    "Validation Accuracy: 0.6875"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replicate Best Hyperparameters: {'learning_rate': 0.5, 'n_estimators': 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for AdaBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67       778\n",
      "           1       0.69      0.71      0.70       822\n",
      "\n",
      "    accuracy                           0.68      1600\n",
      "   macro avg       0.68      0.68      0.68      1600\n",
      "weighted avg       0.68      0.68      0.68      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the AdaBoost classifier with the best hyperparameters\n",
    "best_adaboost_model = AdaBoostClassifier(learning_rate=0.5, n_estimators=200, random_state=42)\n",
    "\n",
    "# Fit the model on the augmented training data\n",
    "best_adaboost_model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "adaboost_predictions = best_adaboost_model.predict(X_val_vec)\n",
    "\n",
    "# Generate the classification report\n",
    "classification_rep = classification_report(y_val, adaboost_predictions)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report for AdaBoost:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for AdaBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91       778\n",
      "           1       0.91      0.94      0.92       822\n",
      "\n",
      "    accuracy                           0.92      1600\n",
      "   macro avg       0.92      0.92      0.92      1600\n",
      "weighted avg       0.92      0.92      0.92      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the AdaBoost classifier with the best hyperparameters\n",
    "best_adaboost_model = AdaBoostClassifier(learning_rate=0.5, n_estimators=200, random_state=42)\n",
    "\n",
    "# Fit the model on the augmented training data\n",
    "best_adaboost_model.fit(X_val_vec, y_val)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "adaboost_predictions = best_adaboost_model.predict(X_val_vec)\n",
    "\n",
    "# Generate the classification report\n",
    "classification_rep = classification_report(y_val, adaboost_predictions)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report for AdaBoost:\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adaboost with svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Convert the lists of integers into strings\n",
    "X_train_str = X_train.apply(lambda x: ' '.join(map(str, x)))\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_vec = vectorizer.fit_transform(X_train_str)\n",
    "\n",
    "# Define the base estimator (SVM)\n",
    "base_estimator = SVC(probability=True, random_state=42)\n",
    "\n",
    "# Initialize the AdaBoost classifier with SVM as the base estimator\n",
    "adaboost_svm_model = AdaBoostClassifier(base_estimator=base_estimator, random_state=42)\n",
    "\n",
    "# Define hyperparameters for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=adaboost_svm_model, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_search.fit(X_train_vec, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Get the best AdaBoost model with SVM as the base estimator\n",
    "best_adaboost_svm_model = grid_search.best_estimator_\n",
    "\n",
    "# Assuming you have validation data (X_val, y_val)\n",
    "# Convert the validation data using the same vectorizer\n",
    "X_val_str = X_val.apply(lambda x: ' '.join(map(str, x)))\n",
    "X_val_vec = vectorizer.transform(X_val_str)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "adaboost_svm_predictions = best_adaboost_svm_model.predict(X_val_vec)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_val, adaboost_svm_predictions)\n",
    "print(\"Validation Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Performance:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.74      0.74      0.74       653\n",
    "           1       0.73      0.73      0.73       627\n",
    "\n",
    "    accuracy                           0.73      1280\n",
    "   macro avg       0.73      0.73      0.73      1280\n",
    "weighted avg       0.73      0.73      0.73      1280\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                                text  label  id\n",
    "0  [16, 231, 543, 5, 15, 43, 8282, 94, 231, 1129,...      1   0\n",
    "1  [16, 4046, 138, 10, 2, 1809, 2007, 3763, 14, 4...      1   1\n",
    "2  [1108, 16550, 3, 6168, 3, 160, 284, 19, 49, 46...      1   2\n",
    "3  [1802, 27, 16, 25, 48, 451, 632, 3, 2, 2164, 2...      1   3\n",
    "4  [16, 19, 302, 93, 97, 43, 952, 118, 1, 16, 528...      1   4\n",
    "                                                text  label    id\n",
    "0  [12, 920, 7, 1266, 28, 9884, 1640, 116, 11, 13...      1  5000\n",
    "1  [783, 397, 253, 5797, 9379, 22, 793, 11838, 10...      1  5001\n",
    "2  [888, 14851, 323, 9, 27, 1377, 584, 195, 3, 13...      1  5002\n",
    "3  [228, 1161, 5815, 379, 9, 941, 10, 2, 316, 4, ...      1  5003\n",
    "4  [736, 19, 37, 813, 45, 6723, 27, 626, 8, 2, 34...      1  5004\n",
    "text\tlabel\tid\n",
    "0\t[16, 231, 543, 5, 15, 43, 8282, 94, 231, 1129,...\t1\t0\n",
    "1\t[16, 4046, 138, 10, 2, 1809, 2007, 3763, 14, 4...\t1\t1\n",
    "2\t[1108, 16550, 3, 6168, 3, 160, 284, 19, 49, 46...\t1\t2\n",
    "3\t[1802, 27, 16, 25, 48, 451, 632, 3, 2, 2164, 2...\t1\t3\n",
    "4\t[16, 19, 302, 93, 97, 43, 952, 118, 1, 16, 528...\t1\t4\n",
    "...\t...\t...\t...\n",
    "4995\t[43, 529, 16, 19, 775, 201, 20, 48, 10, 550, 2...\t0\t4995\n",
    "4996\t[12, 158, 97, 5, 543, 174, 1396, 2, 506, 287, ...\t0\t4996\n",
    "4997\t[15319, 27775, 9, 27, 2847, 7207, 8, 3234, 1, ...\t0\t4997\n",
    "4998\t[16, 373, 177, 76, 5, 35, 1342, 1318, 196, 16,...\t0\t4998\n",
    "4999\t[15, 25, 12264, 20611, 29, 25, 2, 1673, 900, 2...\t0\t4999\n",
    "5000 rows × 3 columns\n",
    "\n",
    "text\tlabel\tid\n",
    "0\t[12, 920, 7, 1266, 28, 9884, 1640, 116, 11, 13...\t1\t5000\n",
    "1\t[783, 397, 253, 5797, 9379, 22, 793, 11838, 10...\t1\t5001\n",
    "2\t[888, 14851, 323, 9, 27, 1377, 584, 195, 3, 13...\t1\t5002\n",
    "3\t[228, 1161, 5815, 379, 9, 941, 10, 2, 316, 4, ...\t1\t5003\n",
    "4\t[736, 19, 37, 813, 45, 6723, 27, 626, 8, 2, 34...\t1\t5004\n",
    "...\t...\t...\t...\n",
    "12995\t[8, 15, 71, 12, 155, 6903, 3, 7, 2300, 352, 37...\t0\t17995\n",
    "12996\t[12, 155, 7, 420, 4, 228, 89, 206, 5157, 10, 5...\t0\t17996\n",
    "12997\t[216, 2, 379, 4, 7, 332, 179, 386, 160, 28, 11...\t0\t17997\n",
    "12998\t[7, 2787, 9, 1026, 7, 5376, 620, 1, 4303, 7, 1...\t0\t17998\n",
    "12999\t[2522, 988, 931, 3, 52, 206, 7143, 988, 931, 3...\t0\t17999\n",
    "13000 rows × 3 columns\n",
    "\n",
    "Missing values in Domain1 Training Data:\n",
    "text     0\n",
    "label    0\n",
    "id       0\n",
    "dtype: int64\n",
    "\n",
    "Missing values in Domain2 Training Data:\n",
    "text     0\n",
    "label    0\n",
    "id       0\n",
    "dtype: int64\n",
    "\n",
    "C:\\Users\\chang\\AppData\\Local\\Temp\\ipykernel_54868\\741347689.py:8: FutureWarning: \n",
    "\n",
    "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
    "\n",
    "  sns.barplot(x=domain1_class_counts.index, y=domain1_class_counts.values, palette='Blues_d')\n",
    "C:\\Users\\chang\\AppData\\Local\\Temp\\ipykernel_54868\\741347689.py:15: FutureWarning: \n",
    "\n",
    "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
    "\n",
    "  sns.barplot(x=domain2_class_counts.index, y=domain2_class_counts.values, palette='Greens_d')\n",
    "\n",
    "0    11500\n",
    "1     1500\n",
    "Name: label, dtype: int64\n",
    "                                                    text  label     id\n",
    "4938   [813, 4, 615, 14, 1134, 13, 340, 32, 532, 3644...      0   9938\n",
    "7148   [28, 347, 2257, 5, 482, 6, 1912, 149, 3, 347, ...      0  12148\n",
    "2704   [12, 216, 7, 2507, 817, 4, 6482, 3869, 57, 18,...      0   7704\n",
    "12157  [12828, 4316, 603, 28, 2, 2475, 3030, 9, 2, 10...      0  17157\n",
    "8791   [12, 437, 27, 1020, 1987, 4, 2, 217, 4, 2, 294...      0  13791\n",
    "0    1500\n",
    "1    1500\n",
    "Name: label, dtype: int64\n",
    "Shape of X_train_vec: (5120, 35061)\n",
    "Shape of X_val_vec: (1280, 35061)\n",
    "LSA-SVM Performance:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.86      0.60      0.71       653\n",
    "           1       0.68      0.90      0.78       627\n",
    "\n",
    "    accuracy                           0.75      1280\n",
    "   macro avg       0.77      0.75      0.74      1280\n",
    "weighted avg       0.77      0.75      0.74      1280\n",
    "\n",
    "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
    "Best hyperparameters: {'lsa__n_components': 150, 'svm__C': 10}\n",
    "Best LSA-SVM Performance:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.86      0.65      0.74       653\n",
    "           1       0.71      0.89      0.79       627\n",
    "\n",
    "    accuracy                           0.77      1280\n",
    "   macro avg       0.78      0.77      0.76      1280\n",
    "weighted avg       0.78      0.77      0.76      1280\n",
    "\n",
    "SVM Performance:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.81      0.74      0.77       653\n",
    "           1       0.75      0.82      0.78       627\n",
    "\n",
    "    accuracy                           0.78      1280\n",
    "   macro avg       0.78      0.78      0.78      1280\n",
    "weighted avg       0.78      0.78      0.78      1280\n",
    "\n",
    "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
    "Best Hyperparameters: {'learning_rate': 0.5, 'n_estimators': 200}\n",
    "Validation Accuracy: 0.68828125\n",
    "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
    "Best Hyperparameters: {'learning_rate': 0.5, 'n_estimators': 300}\n",
    "Validation Accuracy: 0.6875\n",
    "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
    "Best Hyperparameters: {'learning_rate': 1.0, 'n_estimators': 50}\n",
    "Validation Accuracy: 0.6078125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replicate Best Hyperparameters: {'learning_rate': 0.5, 'n_estimators': 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
